Skin Cancer Multimodal Classification
Combining Dermatoscopic Images + Clinical Metadata for Better Diagnosis
ğŸ“Œ About This Project

Skin cancer is one of the most common cancers worldwide. Early detection can significantly improve patient outcomes.

This project builds a deep learning system that classifies skin lesions into 7 diagnostic categories using:

ğŸ–¼ Dermatoscopic images

ğŸ“‹ Clinical metadata (age, sex, lesion location)

Instead of relying only on images, we combine both visual and patient information to build a more robust and clinically meaningful model.

This project was developed as part of the DS606 Data Science Capstone at UMBC.

ğŸ“Š Dataset

We use the HAM10000 dataset (Human Against Machine with 10,000 images).

The dataset contains 10,000 dermatoscopic images categorized into 7 classes:

Code	Diagnosis
akiec	Actinic keratoses
bcc	Basal cell carcinoma
bkl	Benign keratosis
df	Dermatofibroma
nv	Melanocytic nevi
mel	Melanoma
vasc	Vascular lesions
Example Dermatoscopic Images
4

We also utilize available metadata:

Patient age

Sex

Anatomical location

ğŸ¯ Project Goals

The main goals of this project are:

Perform exploratory data analysis (EDA)

Handle severe class imbalance

Train a strong image-based baseline model

Build a multimodal model (image + metadata)

Evaluate performance using balanced metrics

Improve model calibration

Analyze fairness across demographic groups

Provide interpretability using Grad-CAM

ğŸ—ï¸ Project Structure
skin-cancer-multimodal/
â”œâ”€â”€ configs/                     # Hydra/YAML configuration files
â”‚   â”œâ”€â”€ model/                   # EfficientNet, Swin, ConvNeXt configs
â”‚   â”œâ”€â”€ training/                # Learning rates, schedulers, loss functions
â”‚   â”œâ”€â”€ data/                    # Augmentation, preprocessing configs
â”‚   â””â”€â”€ experiment/              # Full experiment presets
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py           # HAM10000Dataset class + multi-modal loader
â”‚   â”‚   â”œâ”€â”€ transforms.py        # Dermatoscopy-specific augmentations
â”‚   â”‚   â”œâ”€â”€ sampler.py           # Class-balanced & group-aware samplers
â”‚   â”‚   â””â”€â”€ preprocessing.py     # Color constancy, hair removal, resizing
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ image_encoder.py     # EfficientNet-B4, Swin-T, ConvNeXt-V2
â”‚   â”‚   â”œâ”€â”€ metadata_encoder.py  # Learned embeddings for clinical metadata
â”‚   â”‚   â”œâ”€â”€ fusion.py            # Late fusion, FiLM, cross-attention
â”‚   â”‚   â”œâ”€â”€ classifier.py        # Final classification head
â”‚   â”‚   â””â”€â”€ ensemble.py          # Model ensembling strategies
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Main training loop with W&B logging
â”‚   â”‚   â”œâ”€â”€ losses.py            # Focal loss, cost-sensitive cross-entropy
â”‚   â”‚   â””â”€â”€ scheduler.py         # Cosine annealing with warm restarts
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Balanced accuracy, macro F1, per-class AUC
â”‚   â”‚   â”œâ”€â”€ calibration.py       # Temperature scaling, reliability diagrams
â”‚   â”‚   â”œâ”€â”€ fairness.py          # Demographic subgroup analysis
â”‚   â”‚   â””â”€â”€ statistical.py       # McNemar, DeLong tests, bootstrapping
â”‚   â”‚
â”‚   â””â”€â”€ interpretability/
â”‚       â”œâ”€â”€ gradcam.py           # Grad-CAM / Grad-CAM++ visualizations
â”‚       â”œâ”€â”€ attention.py         # Attention rollout for transformers
â”‚       â””â”€â”€ shap_analysis.py     # SHAP for metadata branch
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb             # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_Baseline.ipynb        # Image-only baseline experiments
â”‚   â”œâ”€â”€ 03_MultiModal.ipynb      # Multi-modal fusion experiments
â”‚   â”œâ”€â”€ 04_Ablation.ipynb        # Ablation study results
â”‚   â””â”€â”€ 05_Analysis.ipynb        # Final analysis, figures, model card
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ gradio_demo.py           # Interactive inference demo
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                 # Main training entry point
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation pipeline
â”‚   â””â”€â”€ prepare_data.py          # Data download & preprocessing
â”‚
â”œâ”€â”€ model_card.md                # Google-format model card
â”œâ”€â”€ requirements.txt             # Pinned dependencies
â””â”€â”€ README.md                    # Project documentation


ğŸ§  Model Overview
1ï¸âƒ£ Image Encoder

We experiment with modern architectures such as:

EfficientNet-B4

Swin Transformer

ConvNeXt

These models extract high-level visual features from dermatoscopic images.

2ï¸âƒ£ Metadata Encoder

Clinical metadata is encoded using:

Embedding layers

Fully connected neural networks

This allows the model to incorporate patient context into predictions.

3ï¸âƒ£ Fusion Strategy

We explore different ways to combine image and metadata features:

Late fusion (concatenation)

Feature-wise modulation (FiLM)

Cross-attention mechanisms

This multimodal approach improves minority class detection, especially melanoma.

ğŸ“ˆ Evaluation Metrics

Because the dataset is imbalanced, we focus on:

Balanced Accuracy

Macro F1-score

Per-class ROC-AUC

Confusion Matrix

We also evaluate:

Model calibration (temperature scaling)

Reliability diagrams

Demographic fairness (age/sex analysis)

ğŸ” Model Interpretability

In medical AI, interpretability is critical.

We implement Grad-CAM to visualize which regions of the lesion influence predictions.

Example visualization:

4

This helps ensure the model focuses on the lesion area rather than background artifacts.

ğŸ“Š Expected Results
Model	Balanced Accuracy	Macro F1
Image-only Model	~0.80â€“0.83	~0.75â€“0.80
Multimodal Model	~0.85â€“0.88	~0.82â€“0.86

The multimodal setup improves melanoma detection and overall robustness.

âš ï¸ Limitations

Limited dataset size (10k images)

Metadata is incomplete

No external validation dataset

Not approved for clinical deployment

This project is strictly for research and educational purposes.

ğŸš€ Future Improvements

External validation on ISIC dataset

Self-supervised pretraining

Better data augmentation

Uncertainty estimation

Web deployment as a decision-support tool

ğŸ› ï¸ Tech Stack

PyTorch

Hydra

Weights & Biases

NumPy / Pandas

Scikit-learn

SHAP

OpenCV
